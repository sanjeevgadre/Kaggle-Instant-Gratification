---
title: "Part II - Learning Models"
author: "Sanjeev Gadre"
date: "November 08, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = TRUE)
```

Loading the required libraries

```{r libraries, message=FALSE}
library(dplyr)
library(ggplot2)
library(ff)
library(ffbase)
library(biglm)
library(ROCR)
library(glmnet)
library(e1071)
library(MASS)

# Creating ffdir where ff objects can be stored and retrieved
ffdir = paste(getwd(), "/ffdir", sep = "")
if (!dir.exists(ffdir)){dir.create(ffdir)}

```


<!-- Loading utility functions -->

<!-- ```{r utilitity-functions} -->
<!-- save.ffdf(train, dir = "../RDA/traindir", overwrite = TRUE) -->
<!-- save.ffdf(test, dir = "../RDA/testdir", overwrite = TRUE) -->

<!-- train = load.ffdf(dir = "../RDA/traindir") -->
<!--     train = train[["train"]] -->
<!--     open.ffdf(train) -->
<!-- test = load.ffdf(dir = "../RDA/testdir") -->
<!--     test = test[["test"]] -->
<!--     open.ffdf(test) -->
<!-- ``` -->

```{r setup-for-models}
subs = unique(train$wheezy.copper.turtle.magic[])
subs = sample(1:length(subs), 25)

# Matrix to store the performace of the different learning methods for each subset
model.perf = matrix(rep(0, 4*length(subs)), ncol = 4)
colnames(model.perf) = c("Subset", "LR", "NB", "QDA")
model.perf[, "Subset"] = subs

```


### Penalised Logistic Regression Models

1.  We develop penalised logistic regression models for different data subsets formed from different values of `wheezy.copper.turtle.magic`.
2.  We use the *train-val-test* strategy to:
  a.  determine the ideal number of principal components to use in building the model
  b.  estimate the likely test Area Under the Curve metric

```{r multiple-penalised-logit-models, warning=FALSE}
test.auc = 0
rows = 0

for (sub in subs) {
  dat = train[train$wheezy.copper.turtle.magic == sub, ] %>% as.data.frame()
  y = dat$target
  dat = subset(dat, select = -c(target, wheezy.copper.turtle.magic))

  set.seed(sub)
  indx = split(sample(1:nrow(dat)), f = c(rep("train", 6), rep("val", 2), rep("test", 2)))
  
  pca.out = prcomp(dat)
  pve = (pca.out$sdev^2/sum(pca.out$sdev^2)) %>% cumsum()
  comps = c(which(pve <= 0.90) %>% which.max(), 
               which(pve <= 0.95) %>% which.max(),
               which(pve <= 0.99) %>% which.max())
  dat = pca.out$x
  
  auc = rep(0, length(comps))   # Store the val-set auc for models with candidate number of principal components
  j = 1
  for (c in comps) {
    set.seed(c)
    cv.out = cv.glmnet(dat[indx$train, 1:c], y[indx$train], family = "binomial", nfolds = 5)
    best.lambda = cv.out$lambda.min
    model = glmnet(dat[indx$train, 1:c], y[indx$train], family = "binomial", lambda = best.lambda)
    
    prob = predict(model, newx = dat[indx$val, 1:c], type = "response")
    pred = prediction(prob, y[indx$val])
    auc[j] = performance(pred, "auc")@y.values %>% unlist()
    j = j + 1
  }
  
  best.comp = which.max(auc) %>% comps[.]
  
  set.seed(best.comp)
  cv.out = cv.glmnet(dat[-indx$test, 1:best.comp], y[-indx$test], family = "binomial", nfolds = 5)
  best.lambda = cv.out$lambda.min
  
  model = glmnet(dat[-indx$test, 1:best.comp], y[-indx$test], family = "binomial", lambda = best.lambda)
  prob = predict(model, newx = dat[indx$test, 1:best.comp], type = "response")
  
  pred = prediction(prob, y[indx$test])
  perf = performance(pred, "auc")
  perf = perf@y.values %>% unlist() %>% round(., 4)

  model.perf[model.perf[, "Subset"] == sub, "LR"] = perf
  print(paste("The estimated test Area Under the Curve (AUC) for subset", sub,"=", perf))

  test.auc = test.auc + nrow(dat)*perf
  rows = rows + nrow(dat)
} 

print(paste("The weighted estimated test AUC for 25 train datset subsets = ", test.auc/rows))

```

### Naive Bayes Regression Models

1.  We develop naive bayes regression models for different data subsets formed from different values of `wheezy.copper.turtle.magic`.
2.  We use the *train-val-test* strategy to:
  a.  determine the ideal number of principal components to use in building the model
  b.  estimate the likely test Area Under the Curve metric

```{r multiple-naive-bayes-models, warning=FALSE}
test.auc = 0
rows = 0

for (sub in subs) {
  dat = train[train$wheezy.copper.turtle.magic == sub, ] %>% as.data.frame()
  y = dat$target
  dat = subset(dat, select = -c(target, wheezy.copper.turtle.magic))

  set.seed(sub)
  indx = split(sample(1:nrow(dat)), f = c(rep("train", 6), rep("val", 2), rep("test", 2)))
  
  pca.out = prcomp(dat)
  pve = (pca.out$sdev^2/sum(pca.out$sdev^2)) %>% cumsum()
  comps = c(which(pve <= 0.90) %>% which.max(), 
               which(pve <= 0.95) %>% which.max(),
               which(pve <= 0.99) %>% which.max())
  dat = pca.out$x
  
  auc = rep(0, length(comps))   # Store the val-set auc for models with candidate number of principal components
  j = 1
  for (c in comps) {
    set.seed(c)
    model = naiveBayes(dat[indx$train, 1:c], y[indx$train])
    
    prob = predict(model, newdata = dat[indx$val, 1:c], type = "raw")[, "1"]
    pred = prediction(prob, y[indx$val])
    auc[j] = performance(pred, "auc")@y.values %>% unlist()
    j = j + 1
  }
  
  best.comp = which.max(auc) %>% comps[.]
  
  set.seed(best.comp)
  
  model = naiveBayes(dat[-indx$test, 1:best.comp], y[-indx$test])
  prob = predict(model, newdata = dat[indx$test, 1:best.comp], type = "raw")[, "1"]
  
  pred = prediction(prob, y[indx$test])
  perf = performance(pred, "auc")
  perf = perf@y.values %>% unlist() %>% round(., 4)

  model.perf[model.perf[, "Subset"] == sub, "NB"] = perf
  print(paste("The estimated test Area Under the Curve (AUC) for subset", sub,"=", perf))

  test.auc = test.auc + nrow(dat)*perf
  rows = rows + nrow(dat)
} 

print(paste("The weighted estimated test AUC for 25 train datset subsets = ", test.auc/rows))

```

### QDA Regression Models

1.  We tried fitting a QDA model for similar number of components as for Logistic Regression and Naive Bayes models. However, 

```{r multiple-qda-models, warning=FALSE}
test.auc = 0
rows = 0

for (sub in subs) {
  dat = train[train$wheezy.copper.turtle.magic == sub, ] %>% as.data.frame()
  y = dat$target %>% factor()
  dat = subset(dat, select = -c(wheezy.copper.turtle.magic, target)) 

  set.seed(sub)
  indx = split(sample(1:nrow(dat)), f = c(rep("train", 6), rep("val", 2), rep("test", 2)))
  
  pca.out = prcomp(dat)
  pve = (pca.out$sdev^2/sum(pca.out$sdev^2)) %>% cumsum()
  comps = c(which(pve <= 0.80) %>% which.max(), 
               which(pve <= 0.85) %>% which.max(),
               which(pve <= 0.90) %>% which.max())
  dat = pca.out$x
  
  auc = rep(0, length(comps))   # Store the val-set auc for models with candidate number of principal components
  j = 1
  for (c in comps) {
    set.seed(c)
    model = qda(dat[indx$train, 1:c], y[indx$train])
    
    prob = predict(model, newdata = dat[indx$val, 1:c])$posterior[, "1"]
    pred = prediction(prob, y[indx$val])
    auc[j] = performance(pred, "auc")@y.values %>% unlist()
    j = j + 1
  }
  
  best.comp = which.max(auc) %>% comps[.]
  
  set.seed(best.comp)
  
  model = qda(dat[-indx$test, 1:best.comp], y[-indx$test])
  prob = predict(model, newdata = dat[indx$test, 1:best.comp])$posterior[, "1"]
  
  pred = prediction(prob, y[indx$test])
  perf = performance(pred, "auc")
  perf = perf@y.values %>% unlist() %>% round(., 4)

  model.perf[model.perf[, "Subset"] == sub, "QDA"] = perf
  print(paste("The estimated test Area Under the Curve (AUC) for subset", sub,"=", perf))

  test.auc = test.auc + nrow(dat)*perf
  rows = rows + nrow(dat)
} 

print(paste("The weighted estimated test AUC for 25 train datset subsets = ", test.auc/rows))

```
